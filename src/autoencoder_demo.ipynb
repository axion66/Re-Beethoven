{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.autoencoder.vae import AudioAutoencoder,OobleckDecoder,OobleckEncoder\n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "#model_state = torch.load(\"../models/Nov29.pth\")\n",
    "model_state = torch.load(\"../train_log/best_model.pth\")\n",
    "model = AudioAutoencoder(sample_rate=16000,downsampling_ratio=2048).to(\"cuda:0\")\n",
    "model.load_state_dict(model_state)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\nTotal Parameters: {total_params:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "def load_audio(file_path, target_sample_rate=16000):\n",
    "    \"\"\"\n",
    "    Loads an audio file and resamples it to the target sample rate.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the audio file.\n",
    "        target_sample_rate (int): Desired sample rate. Defaults to 16kHz.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Audio waveform as a 1D tensor.\n",
    "    \"\"\"\n",
    "    # Load the audio file\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "    \n",
    "    # If stereo, convert to mono by averaging the channels\n",
    "    if waveform.size(0) > 1:\n",
    "        waveform = waveform.mean(dim=0)\n",
    "    \n",
    "    # Resample if necessary\n",
    "    if sample_rate != target_sample_rate:\n",
    "        resample = T.Resample(orig_freq=sample_rate, new_freq=target_sample_rate)\n",
    "        waveform = resample(waveform)\n",
    "    \n",
    "    return waveform\n",
    "import torchaudio\n",
    "\n",
    "def save_audio(file_path, waveform, sample_rate=16000):\n",
    "    \"\"\"\n",
    "    Saves a waveform as an audio file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to save the audio file (e.g., \"output.mp3\").\n",
    "        waveform (torch.Tensor): Audio waveform as a 1D or 2D tensor.\n",
    "        sample_rate (int): Sample rate of the audio. Defaults to 16kHz.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Ensure waveform is 2D (channel, time), even if mono\n",
    "    if waveform.dim() == 1:\n",
    "        waveform = waveform.unsqueeze(0)\n",
    "    \n",
    "    # Save the audio\n",
    "    torchaudio.save(file_path, waveform, sample_rate)\n",
    "\n",
    "import torch\n",
    "from layers.tools.losses import MultiResolutionSTFTLoss\n",
    "\n",
    "def process_audio_in_chunks(file_path, model, chunk_size=16384*2, target_sample_rate=16000):\n",
    "    \"\"\"\n",
    "    Processes audio in non-overlapping chunks on the GPU to avoid memory overflow.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the input audio file.\n",
    "        model: Preloaded model with `encode` and `decode` methods.\n",
    "        chunk_size (int): Size of each chunk in samples.\n",
    "        target_sample_rate (int): Target sample rate for processing.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The reconstructed audio.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load the audio on CPU\n",
    "    waveform = load_audio(file_path, target_sample_rate).squeeze(0)  # 1D waveform\n",
    "    total_len = waveform.size(0)\n",
    "    \n",
    "    output_chunks = []\n",
    "    start = 0\n",
    "\n",
    "    while start < total_len:\n",
    "        end = min(start + chunk_size, total_len)\n",
    "        chunk = waveform[start:end].to(device).unsqueeze(0).unsqueeze(0)  # Shape (1, 1, chunk_size)\n",
    "\n",
    "        if chunk.shape[-1] > 4000:  # Skip small chunks at the end\n",
    "            with torch.no_grad():\n",
    "                latents = model.encode(chunk)\n",
    "                output_chunk = model.decode(latents)\n",
    "            output_chunks.append(output_chunk.squeeze(0))  # Keep chunks on GPU\n",
    "        start = end  # Move to next chunk\n",
    "\n",
    "    # Concatenate chunks directly on GPU\n",
    "    reconstructed_audio = torch.cat(output_chunks, dim=-1)\n",
    "    return reconstructed_audio\n",
    "\n",
    "# Main processing\n",
    "input_path = \"../demo_dataset/no14/0/audio0.mp3\"\n",
    "reconstructed_audio = process_audio_in_chunks(input_path, model)\n",
    "\n",
    "# Save reconstructed audio\n",
    "save_audio(\"output3.wav\", reconstructed_audio.cpu().unsqueeze(0))\n",
    "\n",
    "# Compute and print STFT loss\n",
    "f = MultiResolutionSTFTLoss()\n",
    "original_audio = load_audio(input_path).to(reconstructed_audio.device).unsqueeze(0).unsqueeze(0)\n",
    "output_audio = reconstructed_audio.unsqueeze(0).unsqueeze(0)\n",
    "error = f(original_audio, output_audio)\n",
    "print(f\"STFT Loss: {error}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
