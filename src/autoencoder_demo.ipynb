{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3q/svznhqyd5q73pvhf_d5zds9w0000gn/T/ipykernel_29320/3857798552.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state = torch.load(\"../models/last.pth\",map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Parameters: 159,088,798\n",
      "Loaded Pretrained autoencoder. (CPU)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ssongjinseobgmail.com/coding/Re-Beethoven/src/layers/autoencoder/vae.py:399: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.ae.load_state_dict(torch.load(autoencoder_state_path, map_location='cpu'))\n"
     ]
    }
   ],
   "source": [
    "from layers.autoencoder.vae import AudioAutoencoder,OobleckDecoder,OobleckEncoder,AutoEncoderWrapper\n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "#model_state = torch.load(\"../models/Nov29.pth\")\n",
    "model_state = torch.load(\"../models/last.pth\",map_location='cpu')\n",
    "model = AudioAutoencoder(sample_rate=16000,downsampling_ratio=2048).to(\"cpu\")\n",
    "model.load_state_dict(model_state)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\nTotal Parameters: {total_params:,}\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "wrapper = AutoEncoderWrapper(autoencoder_state_path=\"../models/final3.pth\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 491520])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 491520])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "def load_audio(file_path, target_sample_rate=16000):\n",
    "    \"\"\"\n",
    "    Loads an audio file and resamples it to the target sample rate.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the audio file.\n",
    "        target_sample_rate (int): Desired sample rate. Defaults to 16kHz.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Audio waveform as a 1D tensor.\n",
    "    \"\"\"\n",
    "    # Load the audio file\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "    \n",
    "    # If stereo, convert to mono by averaging the channels\n",
    "    if waveform.size(0) > 1:\n",
    "        waveform = waveform.mean(dim=0)\n",
    "    \n",
    "    # Resample if necessary\n",
    "    if sample_rate != target_sample_rate:\n",
    "        resample = T.Resample(orig_freq=sample_rate, new_freq=target_sample_rate)\n",
    "        waveform = resample(waveform)\n",
    "    \n",
    "    return waveform\n",
    "import torchaudio\n",
    "\n",
    "def save_audio(file_path, waveform, sample_rate=16000):\n",
    "    \"\"\"\n",
    "    Saves a waveform as an audio file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to save the audio file (e.g., \"output.mp3\").\n",
    "        waveform (torch.Tensor): Audio waveform as a 1D or 2D tensor.\n",
    "        sample_rate (int): Sample rate of the audio. Defaults to 16kHz.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Ensure waveform is 2D (channel, time), even if mono\n",
    "    if waveform.dim() == 1:\n",
    "        waveform = waveform.unsqueeze(0)\n",
    "    \n",
    "    # Save the audio\n",
    "    torchaudio.save(file_path, waveform, sample_rate)\n",
    "\n",
    "import torch\n",
    "from layers.tools.losses import MultiResolutionSTFTLoss\n",
    "\n",
    "\n",
    "# Main processing\n",
    "input_path = \"../dataset/no14/0/audio0.mp3\"\n",
    "\n",
    "    \n",
    "waveform = load_audio(input_path, 16000).unsqueeze(0).to(device)  # 1D waveform\n",
    "waveform = waveform[:, 0:16384*30].unsqueeze(0)\n",
    "print(waveform.shape)\n",
    "out = wrapper.encode_audio(waveform,overlap=0)\n",
    "decode = wrapper.decode_audio(out,overlap=0)\n",
    "decode.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_audio(\"out.wav\", decode.cpu())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
