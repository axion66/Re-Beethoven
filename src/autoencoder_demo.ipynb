{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.autoencoder.vae import AudioAutoencoder,OobleckDecoder,OobleckEncoder,AutoEncoderWrapper\n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "#model_state = torch.load(\"../models/Nov29.pth\")\n",
    "model_state = torch.load(\"../models/final3.pth\",map_location='cpu')\n",
    "model = AudioAutoencoder(sample_rate=16000,downsampling_ratio=2048).to(\"cpu\")\n",
    "model.load_state_dict(model_state)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\nTotal Parameters: {total_params:,}\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "wrapper = AutoEncoderWrapper(autoencoder_state_path=\"../models/final3.pth\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "def load_audio(file_path, target_sample_rate=16000):\n",
    "    \"\"\"\n",
    "    Loads an audio file and resamples it to the target sample rate.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the audio file.\n",
    "        target_sample_rate (int): Desired sample rate. Defaults to 16kHz.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Audio waveform as a 1D tensor.\n",
    "    \"\"\"\n",
    "    # Load the audio file\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "    \n",
    "    # If stereo, convert to mono by averaging the channels\n",
    "    if waveform.size(0) > 1:\n",
    "        waveform = waveform.mean(dim=0)\n",
    "    \n",
    "    # Resample if necessary\n",
    "    if sample_rate != target_sample_rate:\n",
    "        resample = T.Resample(orig_freq=sample_rate, new_freq=target_sample_rate)\n",
    "        waveform = resample(waveform)\n",
    "    \n",
    "    return waveform\n",
    "import torchaudio\n",
    "\n",
    "def save_audio(file_path, waveform, sample_rate=16000):\n",
    "    \"\"\"\n",
    "    Saves a waveform as an audio file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to save the audio file (e.g., \"output.mp3\").\n",
    "        waveform (torch.Tensor): Audio waveform as a 1D or 2D tensor.\n",
    "        sample_rate (int): Sample rate of the audio. Defaults to 16kHz.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Ensure waveform is 2D (channel, time), even if mono\n",
    "    if waveform.dim() == 1:\n",
    "        waveform = waveform.unsqueeze(0)\n",
    "    \n",
    "    # Save the audio\n",
    "    torchaudio.save(file_path, waveform, sample_rate)\n",
    "\n",
    "import torch\n",
    "from layers.tools.losses import MultiResolutionSTFTLoss\n",
    "\n",
    "def process_audio_in_chunks(file_path, model, chunk_size=16384*2, target_sample_rate=16000):\n",
    "    \"\"\"\n",
    "    Processes audio in non-overlapping chunks on the GPU to avoid memory overflow.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the input audio file.\n",
    "        model: Preloaded model with `encode` and `decode` methods.\n",
    "        chunk_size (int): Size of each chunk in samples.\n",
    "        target_sample_rate (int): Target sample rate for processing.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The reconstructed audio.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load the audio on CPU\n",
    "    waveform = load_audio(file_path, target_sample_rate).squeeze(0)  # 1D waveform\n",
    "    total_len = waveform.size(0)\n",
    "    \n",
    "    output_chunks = []\n",
    "    start = 0\n",
    "\n",
    "    while start < total_len:\n",
    "        end = min(start + chunk_size, total_len)\n",
    "        chunk = waveform[start:end].to(device).unsqueeze(0).unsqueeze(0)  # Shape (1, 1, chunk_size)\n",
    "\n",
    "        if chunk.shape[-1] > 4000:  # Skip small chunks at the end\n",
    "            with torch.no_grad():\n",
    "                latents = model.encode(chunk)\n",
    "                output_chunk = model.decode(latents)\n",
    "            output_chunks.append(output_chunk.squeeze(0))  # Keep chunks on GPU\n",
    "        start = end  # Move to next chunk\n",
    "\n",
    "    # Concatenate chunks directly on GPU\n",
    "    reconstructed_audio = torch.cat(output_chunks, dim=-1)\n",
    "    return reconstructed_audio\n",
    "\n",
    "# Main processing\n",
    "input_path = \"../dataset/no14/0/audio0.mp3\"\n",
    "\n",
    "    \n",
    "waveform = load_audio(input_path, 16000).unsqueeze(0).to(device)  # 1D waveform\n",
    "waveform = waveform[:, 0:16384*30].unsqueeze(0)\n",
    "print(waveform.shape)\n",
    "out = wrapper.encode_audio(waveform)\n",
    "decode = wrapper.decode_audio(out)\n",
    "decode.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_audio(\"out.wav\", decode.cpu())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "f = torch.ones((1,640,32))\n",
    "f = nn.Linear(f)\n",
    "num_head = 4\n",
    "\n",
    "f_headed = torch.ones((1,4,640,8))\n",
    "#MHA\n",
    "\n",
    "f_headed = torch.ones((1,640,32))\n",
    "#FFN\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.-1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
